@page "/install"

@rendermode InteractiveServer

<PageTitle>🛈 Info</PageTitle>

<MudContainer>
    <MudText Typo="Typo.h5">Описание</MudText>
    <MudDivider />
    <br />
    <MudText Class="mb-3" Typo="Typo.body1">Иструкция по установке</MudText>
    <MudDivider />
    <br />
<pre style="white-space: pre-wrap;">
1.	Общие сведения
    СПО разработано на языке программирования C#,  запускается на сервере в offline режиме. Оператор взаимодействует с программой через web-браузер клиентского компьютера. Результат обработки доступен через программу просмотра баз данных Спрут PostWorks.
В основе СПО лежат:
•	База данных Oracle Спрут 3.8.
•	Сборки Docker-контейнеров «Whisper» программы-оболочки для запуска LLM «KoboldCpp».
    o	«Whisper» - нейронная сеть для преобразования речи из аудио в текст, обученная на более чем 680 тысячах часов аудиозаписей.
    o	«KoboldCpp» - инструмент с открытым исходным кодом, позволяющий запускать большие языковые модели (LLM) локально на компьютере.
Точность транскрибирования, перевода и оценки зависит от качества аудио, языка оригинала и выбранной модели. Наиболее точно осуществляется распознавание европейских языков. Использование других языков не всегда дает приемлемое качество.
Также СПО позволяет загружать аудиоданные в базу данных Oracle (поддерживаемые форматы входных файлов: mp3, wav, aac, mp4, m4a и др.) и формировать аппаратный журнал в формате Word по заданному шаблону.
    Список поддерживаемых кодеков: "WAVE_FILE", "RPE-LTP", "DAMPS", "GSM", "PCM-128", "QCELP-8", "EVRC", "QCELP-13", "ADPCM", "AMBE.HR_IRIDIUM", "A-LAW", "AMBE_INMARSAT_MM", "APC.HR_INMARSAT_B", "IMBE_INMARSAT_M", "AME", "ACELP_TETRA", "GSM.EFR_ABIS", "GSM.HR_ABIS", "GSM.AMR_ABIS", "GSM_ABIS", "LD-CELP", "E-QCELP", "ATC", "PSI-CELP", "AMBE.GMR1", "AMBE.GMR2", "AMBE.INMARSAT_BGAN", "ADM.UAV", "PCMA", "PCMU", "IPCMA", "IPCMU", "L8", "IL8", "L16", "IL16", "G.723.1", "G.726-32", "G.728", "G.729", "GSM.0610", "ILBC-13", "ILBC-15", "UMTS_AMR", "PDC.FR", "PDC.EFR", "PDC.HR", "IDEN.FR", "APCO-25", "RP-CELP", "IDEN.HR" 

2.	Особенности эксплуатации
Низкая производительность ПЭВМ может ограничить использование больших моделей из-за низких скоростных показателей обработки. Использование младших моделей может привести к частым неверным результатам. Целесообразно запускать данное СПО на оборудовании с видеокартами, имеющими не менее 8 Гб видеопамяти для «Ollama» и не менее 8 Гб для «Whisper» при использовании моделей Whisper Turbo и Gemma 2. Для запуска «Whisper» и «Ollama» на одном ПК рекомендуется видеокарта с 16 Гб видеопамяти. В нашей конфигурации используются 2 ПК с видеокартами по 8 Гб каждая.
База данных Спрут имеет следующие особенности:
•	Поле «Комментарий» ограничено 4000 символами, поэтому текст большого объёма будет записан не полностью.
•	Используемая кодировка w1251 поддерживает только кириллицу и латиницу, поэтому транскрибированный текст перед записью в БД в обязательном порядке переводится. При необходимости получения языка оригинала необходимо выполнить процедуру транскрибирования отдельно.

3.	Системные требования
Для Сервера:
Операционная система: 64-разрядная версия Windows 10 (сборка 19043 или новее).
Оперативная память: не менее 16 Гб.
Свободное место на носителе: не менее 20 Гб.
Видеокарта с объёмом видеопамяти: не менее 8 Гб.
Дополнительно: требуются установка Docker (среда для имитации запуска операционной системы в виде контейнера) и пакет SDK для .NET.
Для клиента: 
Современный Web-браузер с обновлением от 2020 г.

4.	Порядок установки СПО
а) cкопировать папку  «dotnet» на диск С на сервера;
б) установить Docker (загрузка и порядок установки https://docs.docker.com/desktop/install/windows-install) и пакет SDK для .NET (загрузка и порядок установки https://dotnet.microsoft.com/en-us/download/dotnet/);
в) установить Whisper-контейнер (загрузка и порядок установки https://hub.docker.com/r/onerahmet/openai-whisper-asr-webservice);
запустить контейнер и необходимую модель Whisper для транскрибирования (в нашем варианте используется модель Whisper Turbo):
docker run -d --gpus all --name whisper-large-v3-turbo-gpu -p 9000:9000 --restart=always -e ASR_MODEL=large-v3-turbo -e ASR_ENGINE=openai_whisper onerahmet/openai-whisper-asr-webservice:latest-gpu 
запустить модель Whisper для определения языка:
docker run -d --gpus all --name fasterwhisper-tiny-gpu -p 8999:9000 --restart=always -e ASR_MODEL=tiny -e ASR_ENGINE=faster_whisper onerahmet/openai-whisper-asr-webservice:latest-gpu
г) установить KoboldCpp (загрузка и порядок установки https://github.com/LostRuins/koboldcpp/releases/);
запустить необходимую LLM (в нашем варианте используется модель saiga_nemo_12b.Q4_K_M https://huggingface.co/IlyaGusev/saiga_nemo_12b)
Выбор модели определяется в первую очередь исходя из ресурсов сервера.
д) для изменения параметров IP-адреса сервера, др. параметров необходимо внести соответствующие изменения в файл appsettings.json.
е) запустить исполняющий exe-файл в каталоге «dotnet».
ж) запустить браузер, ввести адрес http://localhost:555/ - на сервере или http://адрес-сервера:555/ - на рабочем месте оператора. 


5.	Описание
Использование библиотеки Whisper.Net или других для работы с Whisper также хорошо, но обладает меньшей гибкостью.
Поэтому использование модульных решений на базе Docker или сборки проекта Whisper.cpp более эффективно.
Логика выполнения обработки БД: проверяется поле Notice, если оно не пусное - происходит переход к следующей строке.
Если пустое - извлекается аудиоинформация, конвертируется в нужный формат, транскрибируется, текст анализируется LLM, результат в БД
</pre>

</MudContainer>

@code {


    protected override void OnInitialized()
    {
    }

 
}